{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2  # Added to support visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D as ax\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from aniposelib.boards import CharucoBoard\n",
    "from aniposelib.cameras import Camera, CameraGroup, interpolate_data, resample_points_extra\n",
    "from aniposelib.utils import load_pose2d_fnames, get_initial_extrinsics\n",
    "from aniposelib.boards import merge_rows, extract_points, extract_rtvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R0530_20240401_13-04-14_calibration-charuco-camA.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 211/211 [00:11<00:00, 18.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182 boards detected\n",
      "R0530_20240401_13-04-14_calibration-charuco-camC.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 211/211 [00:20<00:00, 10.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 boards detected\n",
      "R0530_20240401_13-04-14_calibration-charuco-camD.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 211/211 [00:30<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 boards detected\n"
     ]
    }
   ],
   "source": [
    "videos = [['R0530_20240401_13-04-14_calibration-charuco-camA.mp4'],\n",
    "          ['R0530_20240401_13-04-14_calibration-charuco-camC.mp4'],\n",
    "          ['R0530_20240401_13-04-14_calibration-charuco-camD.mp4']]\n",
    "\n",
    "cam_names = ['A', 'C','D']\n",
    "\n",
    "n_cams = len(videos)\n",
    "\n",
    "board = CharucoBoard(10, 7,\n",
    "                     square_length=16, # here, in mm but any unit works\n",
    "                     marker_length=12,\n",
    "                     marker_bits=4, dict_size=50)\n",
    "\n",
    "# make list of cameras\n",
    "cameras = []\n",
    "for name in cam_names:\n",
    "    cam = Camera(name=name)\n",
    "    cameras.append(cam)\n",
    "\n",
    "cgroup = CameraGroup(cameras)\n",
    "\n",
    "all_rows = cgroup.get_rows_videos(videos, board, verbose=True)\n",
    "\n",
    "cgroup.set_camera_sizes_videos(videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling points\n",
      "Resampling points\n",
      "Resampling points\n",
      "Calibration complete\n",
      "visualizing the imgp points\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# stuff in calibrate_rows (changed from self.cameras into my own cameras list constructed from list of names)\n",
    "for rows, camera in zip(all_rows, cameras):\n",
    "    size = camera.get_size()\n",
    "\n",
    "    # Added check for size\n",
    "    assert size is not None, \\\n",
    "        \"Camera with name {} has no specified frame size\".format(camera.get_name())\n",
    "\n",
    "    objp, imgp = board.get_all_calibration_points(rows)\n",
    "    mixed = [(o, i) for (o, i) in zip(objp, imgp) if len(o) >= 9]\n",
    "\n",
    "    # Added check for mixed being empty\n",
    "    if not mixed:\n",
    "        print(f\"No valid calibration points found for camera {camera.get_name()}\")\n",
    "        continue\n",
    "\n",
    "    objp, imgp = zip(*mixed)\n",
    "    matrix = cv2.initCameraMatrix2D(objp, imgp, tuple(size))\n",
    "    camera.set_camera_matrix(matrix.copy())\n",
    "    camera.zero_distortions()\n",
    "\n",
    "\n",
    "    # print(cgroup.get_dicts())\n",
    "\n",
    "    for i, (row, cam) in enumerate(zip(all_rows, cameras)):\n",
    "        all_rows[i] = board.estimate_pose_rows(cam, row)\n",
    "\n",
    "    new_rows = [[r for r in rows if r['ids'].size >= 8] for rows in all_rows]\n",
    "    merged = merge_rows(new_rows)\n",
    "    imgp, extra = extract_points(merged, board, min_cameras=2)\n",
    "\n",
    "    # if init_extrinsics:\n",
    "    rtvecs = extract_rtvecs(merged)\n",
    "    # # if verbose:\n",
    "    # pprint(get_connections(rtvecs, cgroup.get_names()))\n",
    "\n",
    "    rvecs, tvecs = get_initial_extrinsics(rtvecs, cgroup.get_names())\n",
    "    cgroup.set_rotations(rvecs)\n",
    "    cgroup.set_translations(tvecs)\n",
    "\n",
    "    interpolate_data(imgp)\n",
    "    print(\"Resampling points\")\n",
    "    resample_points_extra(imgp, extra)\n",
    "\n",
    "    error = cgroup.bundle_adjust_iter(imgp, extra)\n",
    "\n",
    "print(\"Calibration complete\")\n",
    "print(\"visualizing the imgp points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points saved to imgp_points.txt\n"
     ]
    }
   ],
   "source": [
    "def save_imgp_to_file(imgp, filename):\n",
    "    \"\"\"\n",
    "    Save imgp points to a readable text file.\n",
    "    \"\"\"\n",
    "    # Check if imgp is a numpy array, if not, convert it\n",
    "    if not isinstance(imgp, np.ndarray):\n",
    "        imgp = np.array(imgp)\n",
    "    \n",
    "    # Open the file in write mode\n",
    "    with open(filename, 'w') as file:\n",
    "        # Write a header line for clarity\n",
    "        file.write(\"Image Points (x, y):\\n\")\n",
    "        \n",
    "        # Write each point to the file\n",
    "        for point_set in imgp:\n",
    "            for point in point_set:\n",
    "                file.write(f\"{point[0]}, {point[1]}\\n\")\n",
    "                \n",
    "    print(f\"Points saved to {filename}\")  \n",
    "save_imgp_to_file(imgp, \"imgp_points.txt\")\n",
    "\n",
    "# get a list of the correct frames\n",
    "correct_frames = [[],[],[]]\n",
    "count = 0\n",
    "\n",
    "for camera in all_rows:\n",
    "    # For each camera list, iterate over its items\n",
    "    for item in camera:\n",
    "        # Extract the second number of 'framenum' and append it to the result list\n",
    "        correct_frames[count].append(item['framenum'][1])\n",
    "    \n",
    "    # Increment the count\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_calibration_points(all_obj, all_img):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    for obj, img in zip(all_obj, all_img):\n",
    "        ax.scatter(obj[:, 0], obj[:, 1], obj[:, 2], c='b', marker='o')\n",
    "        ax.scatter(img[:, 0], img[:, 1], np.zeros_like(img[:, 0]), c='r', marker='x')\n",
    "\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title('Calibration Points')\n",
    "    ax.legend(['Object Points', 'Image Points'])\n",
    "    plt.show()\n",
    "\n",
    "def visualize_cameras(all_img):\n",
    "    num_cameras = len(all_img)\n",
    "    for cam_idx, img_points in enumerate(all_img):\n",
    "        plt.figure()\n",
    "        plt.scatter(img_points[:, 0], img_points[:, 1], c='b', marker='o')\n",
    "        plt.title(f\"Camera {cam_idx + 1}\")\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('Y')\n",
    "        plt.axis('equal')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "def visualize_triangulated_points(triangulated_points):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    ax.scatter(triangulated_points[:, 0], triangulated_points[:, 1], triangulated_points[:, 2], c='b', marker='o')\n",
    "\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title('Triangulated Points')\n",
    "    plt.show()\n",
    "\n",
    "def visualize_triangulated_points_in_batches(triangulated_points, batch_size=54):\n",
    "    num_points = triangulated_points.shape[0]\n",
    "    num_batches = (num_points + batch_size - 1) // batch_size  # Ceiling division\n",
    "\n",
    "    def plot_batch(batch_num):\n",
    "        start = batch_num * batch_size\n",
    "        end = min(start + batch_size, num_points)\n",
    "        points_batch = triangulated_points[start:end]\n",
    "\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        ax.scatter(points_batch[:, 0], points_batch[:, 1], points_batch[:, 2], c='b', marker='o')\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.set_title(f'Triangulated Points (Batch {batch_num + 1}/{num_batches})')\n",
    "        plt.show()\n",
    "\n",
    "    batch_num = 0\n",
    "    while True:\n",
    "        plot_batch(batch_num)\n",
    "        user_input = input(\"Enter 'n' for next batch, 'p' for previous batch, or 'q' to quit: \").strip().lower()\n",
    "        if user_input == 'n':\n",
    "            if batch_num < num_batches - 1:\n",
    "                batch_num += 1\n",
    "            else:\n",
    "                print(\"Already at the last batch.\")\n",
    "        elif user_input == 'p':\n",
    "            if batch_num > 0:\n",
    "                batch_num -= 1\n",
    "            else:\n",
    "                print(\"Already at the first batch.\")\n",
    "        elif user_input == 'q':\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 'n', 'p', or 'q'.\")\n",
    "\n",
    "def overlay_points_on_video_write(video_paths, all_img, output_paths, points_per_frame=54, correct_frames=None):\n",
    "    for cam_idx, (video_path, img_points, output_path) in enumerate(zip(video_paths, all_img, output_paths)):\n",
    "        cap = cv2.VideoCapture(video_path[0])\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video {video_path[0]}\")\n",
    "            continue\n",
    "\n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Total frames in input video\n",
    "        \n",
    "        # Define the codec and create VideoWriter object\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "        num_frames = total_frames # OR hardcode: (len(img_points) // points_per_frame) + 100\n",
    "\n",
    "        frame_count = 0\n",
    "\n",
    "        for frame_idx in range(num_frames):\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if not frame_idx in correct_frames[cam_idx]:\n",
    "                out.write(frame)\n",
    "                continue\n",
    "\n",
    "            start_idx = (frame_count) * points_per_frame\n",
    "            end_idx = start_idx + points_per_frame\n",
    "            points = img_points[start_idx:end_idx]\n",
    "\n",
    "            for point in points:\n",
    "                if not np.isnan(point).any():\n",
    "                    x, y = int(point[0]), int(point[1])\n",
    "                    cv2.circle(frame, (x, y), 5, (0, 0, 255), -1)\n",
    "\n",
    "            out.write(frame)\n",
    "            frame_count += 1\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "def overlay_points_on_video_read(video_paths, all_img, output_paths, points_per_frame=54, correct_frames=None):\n",
    "    for cam_idx, (video_path, img_points, output_path) in enumerate(zip(video_paths, all_img, output_paths)):\n",
    "        cap = cv2.VideoCapture(video_path[0])\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video {video_path[0]}\")\n",
    "            continue\n",
    "\n",
    "        # video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Total frames in input video\n",
    "        \n",
    "        # codec and create videoWriter\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "        for frame_idx, frame_num in enumerate(correct_frames[cam_idx]):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num - 1) # 0-based index?\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            start_idx = (frame_idx) * points_per_frame\n",
    "            end_idx = start_idx + points_per_frame\n",
    "            points = img_points[start_idx:end_idx]\n",
    "\n",
    "            for point in points:\n",
    "                if not np.isnan(point).any():\n",
    "                    x, y = int(point[0]), int(point[1])\n",
    "                    cv2.circle(frame, (x, y), 5, (0, 0, 255), -1)\n",
    "\n",
    "            out.write(frame)\n",
    "\n",
    "        cap.release()\n",
    "        out.release()\n",
    "\n",
    "def overlay_points_on_video_source(video_paths, all_img, output_paths, all_rows=None, correct_frames=None):\n",
    "    for cam_idx, (video_path, img_points, output_path) in enumerate(zip(video_paths, all_img, output_paths)):\n",
    "        cap = cv2.VideoCapture(video_path[0])\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video {video_path[0]}\")\n",
    "            continue\n",
    "\n",
    "        # video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        # codec and create videoWriter\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "        for frame_idx, frame_num in enumerate(correct_frames[cam_idx]):\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num) # 0-based index?\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # go into the all_rows and get the filled points from the correct frame\n",
    "            for item in all_rows[cam_idx][frame_idx]['filled']:\n",
    "                first = item[0][0]\n",
    "                last = item[0][1]\n",
    "                point = np.array([first, last])\n",
    "                if not np.isnan(point).any():      \n",
    "                    x, y = int(first), int(last)\n",
    "                    cv2.circle(frame, (x, y), 5, (0, 0, 255), -1)\n",
    "            \n",
    "            out.write(frame)\n",
    "\n",
    "        cap.release()\n",
    "        out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points3d = cgroup.triangulate(imgp)\n",
    "points_3d, picked, p2ds, errors = cgroup.triangulate_ransac(\n",
    "                imgp, min_cams=3, progress=True)\n",
    "\n",
    "output_paths = ['output_camAs.mp4', 'output_camCs.mp4', 'output_camDs.mp4']\n",
    "\n",
    "# Call the function to overlay points on videos\n",
    "# overlay_points_on_video_source(videos, imgp, output_paths, all_rows=all_rows, correct_frames=correct_frames)\n",
    "# visualize_triangulated_points_in_batches(points_3d)\n",
    "# visualize_triangulated_points(points_3d) # should be a plane\n",
    "# visualize_cameras(imgp) # each camera should have a set of points\n",
    "# visualize_calibration_points(objp, imgp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
